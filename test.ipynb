{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silva\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.vgg_16 import BinaryVgg16\n",
    "from trainer.binary_trainer import BinaryTrainer\n",
    "from datasets.image_sharpness_ds import ImageSharpnessDS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev = th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
    "loaded_net = th.load('C:/workspace/Binary_sharpness/saved_models/model_final.pt')\n",
    "net2 = BinaryVgg16(None).to(dev)\n",
    "net2.load_state_dict(loaded_net['model_state_dict'])\n",
    "net2.eval()\n",
    "\n",
    "ds = ImageSharpnessDS('C:/workspace/datasets/binary_sharpness/labels_1.csv',\n",
    "                      'C:/workspace/datasets/binary_sharpness/images',\n",
    "                      transform=th.nn.Sequential(tv.transforms.Resize((128, 128))\n",
    "                                                 ))\n",
    "\n",
    "totalloader = th.utils.data.DataLoader(ds, batch_size=100, shuffle=True, num_workers=0)\n",
    "\n",
    "loop = tqdm(totalloader)\n",
    "\n",
    "result = 0\n",
    "\n",
    "for j, data in enumerate(loop, 0):\n",
    "    img, target = data\n",
    "    target = target.to(dev)\n",
    "    img = img.to(dev)\n",
    "\n",
    "    pred = net2.forward(img)\n",
    "    pred = th.where(pred > 0.5, 1.0, 0.0)\n",
    "\n",
    "    result += th.sum(nn.functional.l1_loss(pred, target, reduction='none')).item()\n",
    "    print(result)\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "[Modify pytorch standard model](https://glassboxmedicine.com/2020/12/08/using-predefined-and-pretrained-cnns-in-pytorch-tutorial-with-code/)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [23]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     23\u001B[0m label \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mimg_labels\u001B[38;5;241m.\u001B[39miloc[i, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m label \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.5\u001B[39m:\n\u001B[1;32m---> 25\u001B[0m     img, label \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     26\u001B[0m     new_ds\u001B[38;5;241m.\u001B[39mappend((img, label))\n\u001B[0;32m     27\u001B[0m     counter \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mC:\\workspace\\Binary_sharpness\\datasets\\image_sharpness_ds.py:25\u001B[0m, in \u001B[0;36mImageSharpnessDS.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     23\u001B[0m img_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_dir, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_labels\u001B[38;5;241m.\u001B[39miloc[idx, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     24\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(img_path)\n\u001B[1;32m---> 25\u001B[0m img \u001B[38;5;241m=\u001B[39m (\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m15\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m16\u001B[39m\n\u001B[0;32m     26\u001B[0m img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(img, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     27\u001B[0m img \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mfrom_numpy(img)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\PIL\\Image.py:675\u001B[0m, in \u001B[0;36mImage.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    673\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    674\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 675\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtobytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ArrayData(new), dtype)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\PIL\\Image.py:718\u001B[0m, in \u001B[0;36mImage.tobytes\u001B[1;34m(self, encoder_name, *args)\u001B[0m\n\u001B[0;32m    715\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m encoder_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m args \u001B[38;5;241m==\u001B[39m ():\n\u001B[0;32m    716\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode\n\u001B[1;32m--> 718\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[38;5;66;03m# unpack data\u001B[39;00m\n\u001B[0;32m    721\u001B[0m e \u001B[38;5;241m=\u001B[39m _getencoder(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode, encoder_name, args)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\PIL\\ImageFile.py:253\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m    248\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage file is truncated \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    249\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(b)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m bytes not processed)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    250\u001B[0m         )\n\u001B[0;32m    252\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[1;32m--> 253\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dev = th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
    "\n",
    "#net = UNetResInc(params).to(dev)\n",
    "net = BinaryVgg16(None).to(dev)\n",
    "optim = th.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
    "#optim = th.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "ds = ImageSharpnessDS('C:/workspace/datasets/binary_sharpness/labels_1.csv',\n",
    "                      'C:/workspace/datasets/binary_sharpness/images',\n",
    "                      transform=th.nn.Sequential(tv.transforms.Resize((128, 128\n",
    "                                                                       ))\n",
    "                                                 ))\n",
    "\n",
    "# count = pd.read_csv('C:/workspace/datasets/binary_sharpness/labels_1.csv')\n",
    "# counter = (len(count['label']) - np.sum(count['label'])) / len(count['label'])\n",
    "\n",
    "new_ds = []\n",
    "counter = 0\n",
    "\n",
    "for i in range(len(ds)):\n",
    "\n",
    "    label = ds.img_labels.iloc[i, 1]\n",
    "    if label < 0.5:\n",
    "        img, label = ds[i]\n",
    "        new_ds.append((img, label))\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "idxs = []\n",
    "\n",
    "while counter > 0:\n",
    "    #print(counter)\n",
    "    randint = np.random.randint(0, len(ds))\n",
    "    label = ds.img_labels.iloc[randint, 1]\n",
    "    if label > 0.5 and randint not in idxs:\n",
    "        new_ds.append(ds[randint])\n",
    "        counter -= 1\n",
    "        idxs.append(randint)\n",
    "\n",
    "# ds, _ = th.utils.data.random_split(ds, [len_keep, len_discard])\n",
    "\n",
    "ds = new_ds\n",
    "\n",
    "len_train = int(0.8 * len(ds))\n",
    "len_test = len(ds) - len_train\n",
    "\n",
    "ds_train, ds_test = th.utils.data.random_split(ds, [len_train, len_test])\n",
    "\n",
    "trainloader = th.utils.data.DataLoader(ds_train, 100, shuffle=True, num_workers=0)\n",
    "testloader = th.utils.data.DataLoader(ds_test, 25, shuffle=True, num_workers=0)\n",
    "\n",
    "trainer = BinaryTrainer(net, dev, criterion, optim)\n",
    "\n",
    "for i in range(100):\n",
    "    img, tar, pre = trainer.train_epoch(trainloader)\n",
    "    img, tar, pre = trainer.test(testloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "th.save(net.state_dict(), 'C:/workspace/Binary_sharpness/saved_models/model_1.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    img, tar, pre = trainer.train_epoch(trainloader)\n",
    "    img, tar, pre = trainer.test(testloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "th.save({\n",
    "        'epoch': trainer.epochs,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'loss': trainer.test_losses,\n",
    "        }, 'C:/workspace/Binary_sharpness/saved_models/model_' + str(trainer.epochs) + '.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    img, tar, pre = trainer.train_epoch(trainloader)\n",
    "    img, tar, pre = trainer.test(testloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "th.save({\n",
    "        'ds_train': ds_train,\n",
    "        'ds_test': ds_test,\n",
    "        'epoch': trainer.epochs,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'trainer': trainer,\n",
    "        'loss': trainer.test_losses,\n",
    "        }, 'C:/workspace/Binary_sharpness/saved_models/model_' + str(trainer.epochs) + '.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    img, tar, pre = trainer.train_epoch(trainloader)\n",
    "    img, tar, pre = trainer.test(testloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "th.save({\n",
    "        'epoch': trainer.epochs,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'loss': trainer.test_losses,\n",
    "        }, 'C:/workspace/Binary_sharpness/saved_models/model_' + str(trainer.epochs) + '.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    img, tar, pre = trainer.train_epoch(trainloader)\n",
    "    img, tar, pre = trainer.test(testloader)\n",
    "    if trainer.epochs % 10 == 0:\n",
    "        th.save({\n",
    "        'epoch': trainer.epochs,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'loss': trainer.test_losses,\n",
    "        }, 'C:/workspace/Binary_sharpness/saved_models/model_' + str(trainer.epochs) + '.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "th.save({\n",
    "        'ds_train': ds_train,\n",
    "        'ds_test': ds_test,\n",
    "        'epoch': trainer.epochs,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'trainer': trainer,\n",
    "        'loss': trainer.test_losses,\n",
    "        }, 'C:/workspace/Binary_sharpness/saved_models/model_final.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_net = th.load('C:/workspace/Binary_sharpness/saved_models/model_final.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net2 = BinaryVgg16(None).to(dev)\n",
    "net2.load_state_dict(loaded_net['model_state_dict'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net2.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "loaded_net = th.load('C:/workspace/Binary_sharpness/saved_models/model_final.pt')\n",
    "net2 = BinaryVgg16(None).to(dev)\n",
    "net2.load_state_dict(loaded_net['model_state_dict'])\n",
    "net2.eval()\n",
    "\n",
    "totalloader = trainloader = th.utils.data.DataLoader(ImageSharpnessDS('C:/workspace/datasets/binary_sharpness/labels_1.csv',\n",
    "                      'C:/workspace/datasets/binary_sharpness/images',\n",
    "                      transform=th.nn.Sequential(tv.transforms.Resize((128, 128\n",
    "                                                                       ))\n",
    "                                                 )), 100, shuffle=True)\n",
    "\n",
    "result = 0\n",
    "\n",
    "for j, data in enumerate(totalloader, 0):\n",
    "    img, target = data\n",
    "    target = target.to(dev)\n",
    "    img = img.to(dev)\n",
    "\n",
    "    pred = net2.forward(img)\n",
    "\n",
    "    loss = th.sum(th.abs(target - pred))\n",
    "\n",
    "    result += loss\n",
    "\n",
    "print(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}