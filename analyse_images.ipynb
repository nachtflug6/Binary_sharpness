{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silva\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.vgg_16 import BinaryVgg16\n",
    "from trainer.binary_trainer import BinaryTrainer\n",
    "from datasets.image_sharpness_ds import ImageSharpnessDS\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def plot_sharpness_loss(result):\n",
    "    result = np.array(result)\n",
    "    result = result.flatten()\n",
    "    result = np.sort(result)\n",
    "    result = result[::-1]\n",
    "    plt.plot(result)\n",
    "    plt.ylim((0, 1))\n",
    "    plt.title('Sharpness Loss Sorted')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def transform_results_vector(result_list, item_enable=False):\n",
    "    result_vector = []\n",
    "    for vec in result_list:\n",
    "        for item in vec:\n",
    "            if item_enable:\n",
    "                result_vector.append(item.item())\n",
    "            else:\n",
    "                result_vector.append(item)\n",
    "\n",
    "    return result_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [03:00<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "dev = th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n",
    "loaded_net = th.load('C:/workspace/Binary_sharpness/saved_models/model_final.pt')\n",
    "net2 = BinaryVgg16(None).to(dev)\n",
    "net2.load_state_dict(loaded_net['model_state_dict'])\n",
    "net2.eval()\n",
    "\n",
    "ds = ImageSharpnessDS('C:/workspace/datasets/binary_sharpness/labels_1.csv',\n",
    "                      'C:/workspace/datasets/binary_sharpness/images',\n",
    "                      transform=th.nn.Sequential(tv.transforms.Resize((128, 128))\n",
    "                                                 ))\n",
    "\n",
    "totalloader = th.utils.data.DataLoader(ds, batch_size=75, shuffle=True, num_workers=0)\n",
    "\n",
    "loop = tqdm(totalloader)\n",
    "\n",
    "names = []\n",
    "labels = []\n",
    "preds = []\n",
    "losses = []\n",
    "\n",
    "for j, data in enumerate(loop, 0):\n",
    "    img, target, name = data\n",
    "    target = target.to(dev)\n",
    "    img = img.to(dev)\n",
    "\n",
    "    label_np = target.cpu().detach().numpy()\n",
    "\n",
    "    pred = net2.forward(img)\n",
    "\n",
    "    pred_np = pred.cpu().detach().numpy()\n",
    "    loss = nn.functional.l1_loss(pred, target, reduction='none')\n",
    "    loss_np = loss.cpu().detach().numpy()\n",
    "\n",
    "    names.append(name)\n",
    "    labels.append(label_np)\n",
    "    preds.append(pred_np)\n",
    "    losses.append(loss_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name  label  predictions          loss\n",
      "0         1643_i49_s11_r1_z5_c1.png    1.0     0.997776  2.223551e-03\n",
      "1       16387_i608_s4_r2_z16_c1.png    0.0     0.024053  2.405262e-02\n",
      "2         1506_i44_s11_r1_z5_c0.png    1.0     0.999987  1.347065e-05\n",
      "3        9445_i321_s8_r1_z13_c1.png    1.0     1.000000  0.000000e+00\n",
      "4        3558_i135_s2_r1_z11_c0.png    1.0     0.999999  8.344650e-07\n",
      "...                             ...    ...          ...           ...\n",
      "20667     9119_i310_s8_r1_z3_c1.png    1.0     0.986830  1.316994e-02\n",
      "20668    4244_i157_s3_r1_z14_c0.png    1.0     1.000000  1.192093e-07\n",
      "20669     3719_i140_s2_r1_z6_c1.png    1.0     0.999954  4.649162e-05\n",
      "20670     5683_i204_s4_r1_z2_c1.png    1.0     0.981621  1.837891e-02\n",
      "20671  11419_i380_s10_r2_z14_c1.png    1.0     0.999996  3.695488e-06\n",
      "\n",
      "[20672 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "result_table = pd.DataFrame().assign(name=transform_results_vector(names, item_enable=False),\n",
    "                                     label=transform_results_vector(labels, item_enable=True),\n",
    "                                     predictions=transform_results_vector(preds, item_enable=True),\n",
    "                                     loss=transform_results_vector(losses, item_enable=True))\n",
    "\n",
    "print(result_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name  label   predictions  loss\n",
      "17058     4978_i181_s3_r1_z7_c0.png    1.0  4.106361e-10   1.0\n",
      "17405     4982_i181_s3_r1_z9_c0.png    1.0  1.009961e-09   1.0\n",
      "12539    4992_i181_s3_r1_z14_c0.png    1.0  1.035908e-08   1.0\n",
      "15311    4986_i181_s3_r1_z11_c0.png    1.0  1.705591e-09   1.0\n",
      "18739    4990_i181_s3_r1_z13_c0.png    1.0  5.806085e-09   1.0\n",
      "...                             ...    ...           ...   ...\n",
      "5149    11438_i381_s10_r2_z7_c0.png    1.0  1.000000e+00   0.0\n",
      "15620  11042_i369_s10_r2_z13_c0.png    1.0  1.000000e+00   0.0\n",
      "19885  13214_i433_s12_r2_z11_c0.png    1.0  1.000000e+00   0.0\n",
      "9135     5880_i209_s4_r1_z16_c0.png    1.0  1.000000e+00   0.0\n",
      "11411  12408_i409_s11_r2_z16_c0.png    1.0  1.000000e+00   0.0\n",
      "\n",
      "[20672 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "result_table = result_table.sort_values(by='loss', ascending=False)\n",
    "print(result_table)\n",
    "result_table.to_csv('C:/workspace/datasets/binary_sharpness/results_1.csv', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}